{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------- TIM Python Client - Tutorial -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial notebook you can find a detailed explanation on how to use each of the available functions in the Python Client for TIM.  \n",
    "For more information visit our documentation: https://docs.tangent.works/TIM-on-Platforms/Python-Client/Overview/\n",
    "or PyPi: https://pypi.org/project/tim-client/  \n",
    "Navigate to any section of this notebook through the overview below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Overview'></a>\n",
    "## __Overview__  \n",
    "&emsp;[0. Setup](#0.0.0)  \n",
    "&emsp;[1. Supporting Files](#1.0.0)  \n",
    "&emsp;&emsp;[1.1 Data](#1.1.0)  \n",
    "&emsp;&emsp;&emsp;[1.1.1 Data file](#1.1.1)  \n",
    "&emsp;&emsp;&emsp;[1.1.2 Dataset Configuration](#1.1.2)  \n",
    "&emsp;&emsp;&emsp;[1.1.3 Update Dataset Configuration](#1.1.3)  \n",
    "&emsp;&emsp;[1.2 Forecasting](#1.2.0)  \n",
    "&emsp;&emsp;&emsp;[1.2.1 Forecast Build Model Configuration](#1.2.1)  \n",
    "&emsp;&emsp;&emsp;[1.2.2 Forecast Predict Configuration](#1.2.2)  \n",
    "&emsp;&emsp;&emsp;[1.2.3 Forecast Rebuild Configuration](#1.2.3)  \n",
    "&emsp;&emsp;[1.3 Anomaly Detection](#1.3.0)  \n",
    "&emsp;&emsp;&emsp;[1.3.1 Detection Build Model Configuration](#1.3.1)  \n",
    "&emsp;&emsp;&emsp;[1.3.2 Detection Detect Configuration](#1.3.2)  \n",
    "&emsp;&emsp;&emsp;[1.3.3 Detection Rebuild Configuration](#1.3.3)   \n",
    "&emsp;[2. Functions](#2.0.0)  \n",
    "&emsp;&emsp;[2.1 Workflow](#2.1.0)  \n",
    "&emsp;&emsp;&emsp;[2.1.1 Get Workspaces](#2.1.1)  \n",
    "&emsp;&emsp;&emsp;[2.1.2 Get Datasets](#2.1.2)  \n",
    "&emsp;&emsp;&emsp;[2.1.3 Get Dataset Versions](#2.1.3)  \n",
    "&emsp;&emsp;&emsp;[2.1.4 Get Forecasting Jobs](#2.1.4)  \n",
    "&emsp;&emsp;&emsp;[2.1.5 Get Anomaly Detection Jobs](#2.1.5)  \n",
    "&emsp;&emsp;[2.2 Dataset Management](#2.2.0)  \n",
    "&emsp;&emsp;&emsp;[2.2.1 Upload Dataset](#2.2.1)  \n",
    "&emsp;&emsp;&emsp;[2.2.2 Delete Dataset](#2.2.2)  \n",
    "&emsp;&emsp;&emsp;[2.2.3 Update Dataset](#2.2.3)  \n",
    "&emsp;&emsp;[2.3 Forecasting](#2.3.0)  \n",
    "&emsp;&emsp;&emsp;[2.3.1 Build Forecasting Model](#2.3.1)  \n",
    "&emsp;&emsp;&emsp;[2.3.2 Execute Forecast](#2.3.2)  \n",
    "&emsp;&emsp;&emsp;[2.3.3 Build Forecasting Model & Execute](#2.3.3)  \n",
    "&emsp;&emsp;&emsp;[2.3.4 Create Forecast](#2.3.4)  \n",
    "&emsp;&emsp;&emsp;[2.3.5 Create Forecast & Execute](#2.3.5)  \n",
    "&emsp;&emsp;&emsp;[2.3.6 Rebuild Forecasting Model](#2.3.6)  \n",
    "&emsp;&emsp;&emsp;[2.3.7 Rebuild Forecasting Model & Execute](#2.3.7)  \n",
    "&emsp;&emsp;&emsp;[2.3.8 Clean Forecast](#2.3.8)  \n",
    "&emsp;&emsp;&emsp;[2.3.9 Get Forecast Results](#2.3.9)  \n",
    "&emsp;&emsp;&emsp;[2.3.10 Delete Forecast](#2.3.10)  \n",
    "&emsp;&emsp;[2.4 Anomaly Detection](#2.4.0)  \n",
    "&emsp;&emsp;&emsp;[2.4.1 Build Anomaly Detection Model](#2.4.1)  \n",
    "&emsp;&emsp;&emsp;[2.4.2 Execute Anomaly Detection](#2.4.2)  \n",
    "&emsp;&emsp;&emsp;[2.4.3 Build Anomaly Detection Model & Execute](#2.4.3)  \n",
    "&emsp;&emsp;&emsp;[2.4.4 Create Anomaly Detection](#2.4.4)  \n",
    "&emsp;&emsp;&emsp;[2.4.5 Create Anomaly Detection & Execute](#2.4.5)  \n",
    "&emsp;&emsp;&emsp;[2.4.6 Rebuild Anomaly Detection Model](#2.4.6)  \n",
    "&emsp;&emsp;&emsp;[2.4.7 Rebuild Anomaly Detection Model & Execute](#2.4.7)  \n",
    "&emsp;&emsp;&emsp;[2.4.8 Get Anomaly Detection Results](#2.4.8)  \n",
    "&emsp;&emsp;&emsp;[2.4.9 Delete Anomaly Detection](#2.4.9)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0.0.0'></a>\n",
    "# 0. Setup\n",
    "Import the libraries necessary to run this notebook and set up the python client for TIM.\n",
    "Make sure to fill in your credentials for TIM in the JSON file accompanying this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tim import Tim\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_credentials = json.load(open('tim_credentials.json'))\n",
    "client = Tim(email=tim_credentials['email'],password=tim_credentials['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.0.0'></a>\n",
    "# 1. Supporting Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you can collect an example dataset and generate the configurations necessary for the functions in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1.0'></a>\n",
    "## 1.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1.1'></a>\n",
    "### 1.1.1 Data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load this example dataset in this notebook and use it to try out the dataset management functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_input_df = pd.read_csv('python_client_tutorial.csv')\n",
    "timestamp = 'Date'\n",
    "target_variable = 'Sales'\n",
    "predictor_candidates = [s for s in list(tim_input_df.columns) if s not in [timestamp,target_variable]]\n",
    "tim_input_df = tim_input_df[[timestamp,target_variable]+predictor_candidates].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate a dataset update to try out the dataset update function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = tim_input_df.iloc[-14:-7].copy()\n",
    "update_df['Date'] = pd.date_range(start=update_df.iloc[-1]['Date'],periods=8,freq='D')[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1.2'></a>\n",
    "### 1.1.2 Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configuration = {\n",
    "#     \"timestampFormat\": \"yyyy-mm-dd HH:MM:SS.sss\",\n",
    "#     \"timestampColumn\": 1,\n",
    "#     \"decimalSeparator\": \".\",\n",
    "#     \"csvSeparator\": \",\",\n",
    "#     \"timeZone\": \"Z\",\n",
    "#     \"name\": \"Vienna\",\n",
    "#     \"description\": \"Electricity consumption\",\n",
    "#     \"samplingPeriod\": {\n",
    "#         \"baseUnit\": \"Hour\",\n",
    "#         \"value\": 1\n",
    "#     },\n",
    "#     \"workspace\": {\n",
    "#         \"id\": \"ef47117c-5408-4603-9d6f-735f45a74ff3\"\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1.3'></a>\n",
    "### 1.1.3 Update Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dataset_configuration = {\n",
    "#     \"timestampFormat\": \"yyyy-mm-dd HH:MM:SS.sss\",\n",
    "#     \"timestampColumn\": 1,\n",
    "#     \"decimalSeparator\": \".\",\n",
    "#     \"csvSeparator\": \",\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2.0'></a>\n",
    "## 1.2 Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2.1'></a>\n",
    "### 1.2.1 Forecast Build Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_build_model_configuration = {\n",
    "#             \"name\": \"My first forecast job\",\n",
    "#             \"useCase\": {\"id\":\"useCaseId\"},\n",
    "#             \"experiment\": {\"id\":\"experimentId\"},\n",
    "            \"configuration\": {\n",
    "                \"predictionTo\": {\"baseUnit\": \"Sample\",\"value\": 7},\n",
    "#                 \"predictionFrom\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                 \"modelQuality\": \"Combined\",\n",
    "#                 \"normalization\": True,\n",
    "#                 \"maxModelComplexity\": 50,\n",
    "#                 \"features\": [\n",
    "#                    \"ExponentialMovingAverage\",\n",
    "#                     \"RestOfWeek\",\n",
    "#                     \"Periodic\",\n",
    "#                     \"Intercept\",\n",
    "#                     \"PiecewiseLinear\",\n",
    "#                     \"TimeOffsets\",\n",
    "#                     \"Polynomial\",\n",
    "#                     \"Identity\",\n",
    "#                     \"PublicHolidays\",      \n",
    "# #                     \"SimpleMovingAverage\",\n",
    "# #                     \"Month\",\n",
    "# #                     \"Trend\",\n",
    "# #                     \"DayOfWeek\",\n",
    "# #                     \"Fourier\",\n",
    "#                     ],\n",
    "#                 \"dailyCycle\": False,\n",
    "#                 \"allowOffsets\": True,\n",
    "#                 \"offsetLimit\": {\"type\": \"Explicit\",\"value\": 0},\n",
    "#                 \"memoryLimitCheck\": True,\n",
    "#                  \"predictionIntervals\": 90,\n",
    "#                  \"predictionBoundaries\": {\"type\": \"Explicit\",\n",
    "#                      \"maxValue\": 750,\n",
    "#                     \"minValue\": 100\n",
    "#                      },\n",
    "#                 \"rollingWindow\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                 \"backtest\": \"All\"\n",
    "                },\n",
    "#             \"data\": {\n",
    "#                 \"version\": {\"id\":\"versionId\"},\n",
    "#                 \"inSampleRows\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                 \"outOfSampleRows\": {\"baseUnit\": \"Sample\",\"value\": 7*8},\n",
    "#                 \"imputation\": {\"type\": \"Linear\",\"maxGapLength\": 6},\n",
    "#                 \"columns\": [\n",
    "#                     1,\n",
    "#                     3,\n",
    "#                     \"wind\"\n",
    "#                     ],\n",
    "#                 \"targetColumn\": \"y\",\n",
    "#                 \"holidayColumn\": holidayColumn,\n",
    "#                 \"timeScale\": {\"baseUnit\": \"Hour\",\"value\": 1},\n",
    "#                 \"aggregation\": \"Mean\",\n",
    "#                 \"dataAlignment\": {\n",
    "#                     \"lastTargetTimestamp\": {},\n",
    "#                     \"dataUntil\": [\n",
    "#                         {\"baseUnit\": \"Hour\",\"offset\": -2,\"column\": \"Sales\"}\n",
    "#                     ]\n",
    "#                 },\n",
    "#                 \"preprocessors\": [\n",
    "#                     {\"type\": \"CategoryFilter\"}\n",
    "#                 ]\n",
    "#             }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2.2'></a>\n",
    "### 1.2.2 Forecast Predict Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_predict_configuration = {\n",
    "#             \"name\": \"My first forecast job\",\n",
    "#             \"experiment\": {\"id\":\"experimentId\"},\n",
    "            \"configuration\": {\n",
    "                \"predictionTo\": {\"baseUnit\": \"Sample\",\"value\": 7},\n",
    "#                 \"predictionFrom\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                  \"predictionBoundaries\": {\"type\": \"Explicit\",\n",
    "#                      \"maxValue\": 750,\n",
    "#                     \"minValue\": 100\n",
    "#                      },\n",
    "#                 \"rollingWindow\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "                },\n",
    "#             \"data\": {\n",
    "#                 \"version\": {\"id\":\"versionId\"},\n",
    "#                 \"outOfSampleRows\": {\"baseUnit\": \"Sample\",\"value\": 28},\n",
    "#                 \"imputation\": {\"type\": \"Linear\",\"maxGapLength\": 6},\n",
    "#                 \"preprocessors\": [\n",
    "#                     {\"type\": \"CategoryFilter\"}\n",
    "#                 ],\n",
    "#             }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2.3'></a>\n",
    "### 1.2.3 Forecast Rebuild Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_rebuild_configuration = {\n",
    "#     \"name\": \"My first forecast job\",\n",
    "#     \"experiment\": {\"id\": \"f2d3d8ee-3c05-4df7-abcf-b13f44073f42\"},\n",
    "    \"configuration\": {\n",
    "        \"predictionTo\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#         \"predictionFrom\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#         \"modelQuality\": \"Combined\",\n",
    "#         \"normalization\": True,\n",
    "#         \"maxModelComplexity\": 2,\n",
    "#         \"features\": [\n",
    "#             \"ExponentialMovingAverage\",\n",
    "#             \"RestOfWeek\",\n",
    "#             \"Periodic\",\n",
    "#             \"Intercept\",\n",
    "#             \"PiecewiseLinear\",\n",
    "#             \"TimeOffsets\",\n",
    "#             \"Polynomial\",\n",
    "#             \"Identity\",\n",
    "#             \"PublicHolidays\",      \n",
    "#             \"SimpleMovingAverage\",\n",
    "#             \"Month\",\n",
    "#             \"Trend\",\n",
    "#             \"DayOfWeek\",\n",
    "#             \"Fourier\",\n",
    "#         ]\n",
    "#         \"allowOffsets\": True,\n",
    "#         \"offsetLimit\": {\"type\": \"Explicit\",\"value\": 0},\n",
    "#         \"memoryLimitCheck\": True,\n",
    "#         \"rebuildingPolicy\": {\n",
    "#             \"type\": \"NewSituations\",\n",
    "#             \"time\": {\"baseUnit\": \"Sample\",\"value\": 1}\n",
    "#         },\n",
    "#         \"predictionBoundaries\": {\"type\": \"Explicit\",\"maxValue\": 0,\"minValue\": 100},\n",
    "#         \"rollingWindow\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#         \"backtest\": \"All\"\n",
    "    },\n",
    "#     \"data\": {\n",
    "#         \"version\": {\"id\": \"a74ae716-a86e-47f0-8a50-d8b21d6d7dd6\"},\n",
    "#         \"imputation\": {\"type\": \"Linear\",\"maxGapLength\": 6},\n",
    "#         \"columns\": [\n",
    "#             1,\n",
    "#             3,\n",
    "#             \"wind\"\n",
    "#         ],\n",
    "#         \"dataAlignment\": {\n",
    "#             \"lastTargetTimestamp\": {},\n",
    "#             \"dataUntil\": [\n",
    "#                 {\"baseUnit\": \"Hour\",\"offset\": -2,\"column\": \"Sales\"}\n",
    "#             ]\n",
    "#         },\n",
    "#         \"preprocessors\": [\n",
    "#             {\"type\": \"CategoryFilter\"}\n",
    "#         ]\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3.0'></a>\n",
    "## 1.3 Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3.1'></a>\n",
    "### 1.3.1 Detection Build Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_build_model_configuration = {\n",
    "#     \"name\": \"My first anomaly build-model job\",\n",
    "#     \"useCase\": {\"id\": \"47c21df1-f5e5-4310-924c-5ea4c9adcbb2\"},\n",
    "#     \"experiment\": {\"id\": \"f2d3d8ee-3c05-4df7-abcf-b13f44073f42\"},\n",
    "#     \"configuration\": {\n",
    "#         \"domainSpecifics\": [\n",
    "#             {\n",
    "#                 \"perspective\": \"Residual\",\n",
    "#                 \"sensitivity\": 0,\n",
    "#                 \"minSensitivity\": 0,\n",
    "#                 \"maxSensitivity\": 0\n",
    "#             }\n",
    "#         ],\n",
    "#         \"normalBehaviorModel\": {\n",
    "#             \"useNormalBehaviorModel\": True,\n",
    "#             \"normalization\": True,\n",
    "#             \"maxModelComplexity\": 50,\n",
    "#             \"features\": [\n",
    "#                 \"ExponentialMovingAverage\",\n",
    "#                 \"TimeOffsets\",\n",
    "#                 \"Identity\",\n",
    "#                 \"Intercept\"\n",
    "#             ],\n",
    "#             \"dailyCycle\": true,\n",
    "#             \"useKPIoffsets\": true,\n",
    "#             \"allowOffsets\": true,\n",
    "#             \"offsetLimit\": {\"type\": \"Explicit\",\"value\": 0}\n",
    "#         },\n",
    "#         \"anomalousBehaviorModel\": {\n",
    "#             \"maxModelComplexity\": 15,\n",
    "#             \"detectionIntervals\": [\n",
    "#                 {\"type\": \"Hour\",\"value\": \"8-16\"}\n",
    "#             ]\n",
    "#         }\n",
    "#     },\n",
    "#     \"data\": {\n",
    "#         \"version\": {\"id\": \"a74ae716-a86e-47f0-8a50-d8b21d6d7dd6\"},\n",
    "#         \"rows\": {\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1}, #{\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1} or [{\"from\": \"yyyy-mm-dd HH:MM:SS\",\"to\": \"yyyy-mm-dd HH:MM:SS\"}]\n",
    "#         \"columns\": [\n",
    "#             1,\n",
    "#             3,\n",
    "#             \"wind_speed\"\n",
    "#         ],\n",
    "#         \"KPIColumn\": \"rotor_speed\",\n",
    "#         \"holidayColumn\": \"PH\",\n",
    "#         \"labelColumn\": \"LABEL\",\n",
    "#         \"imputation\": {\"type\": \"LOCF\",\"maxGapLength\": 6},\n",
    "#         \"timeScale\": {\"baseUnit\": \"Hour\",\"value\": 1},\n",
    "#         \"aggregation\": \"Mean\",\n",
    "#         \"updates\": [\n",
    "#             {\n",
    "#                 \"column\": \"wind_speed\",\n",
    "#                 \"updateTime\": [\n",
    "#                     {\"type\": \"Hour\",\"value\": \"1,12,23\"}\n",
    "#                 ],\n",
    "#                 \"updateUntil\": {\"baseUnit\": \"Hour\",\"offset\": -2}\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3.2'></a>\n",
    "### 1.3.2 Detection Detect Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_detect_configuration = {\n",
    "#     \"name\": \"My first anomaly detect job\",\n",
    "#     \"experiment\": {\"id\": \"f2d3d8ee-3c05-4df7-abcf-b13f44073f42\"},\n",
    "#     \"data\": {\n",
    "#         \"version\": {\"id\": \"a74ae716-a86e-47f0-8a50-d8b21d6d7dd6\"},\n",
    "#         \"rows\": {\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1}, #{\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1} or [{\"from\": \"yyyy-mm-dd HH:MM:SS\",\"to\": \"yyyy-mm-dd HH:MM:SS\"}]\n",
    "#         \"imputation\": {\"type\": \"LOCF\",\"maxGapLength\": 6}\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3.3'></a>\n",
    "### 1.3.3 Detection Rebuild Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_rebuild_configuration = {\n",
    "#     \"name\": \"My first anomaly rebuild-model job\",\n",
    "#     \"experiment\": {\"id\": \"f2d3d8ee-3c05-4df7-abcf-b13f44073f42\"},\n",
    "#     \"configuration\": {\n",
    "#         \"domainSpecifics\": [\n",
    "#             {\n",
    "#                 \"perspective\": \"Residual\",\n",
    "#                 \"sensitivity\": 0,\n",
    "#                 \"minSensitivity\": 0,\n",
    "#                 \"maxSensitivity\": 0\n",
    "#             }\n",
    "#         ],\n",
    "#         \"rebuildType\": \"All\"\n",
    "#     },\n",
    "#     \"data\": {\n",
    "#         \"version\": {\"id\": \"a74ae716-a86e-47f0-8a50-d8b21d6d7dd6\"},\n",
    "#         \"rows\": {\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1}, #{\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1} or [{\"from\": \"yyyy-mm-dd HH:MM:SS\",\"to\": \"yyyy-mm-dd HH:MM:SS\"}]\n",
    "#         \"imputation\": {\"type\": \"LOCF\",\"maxGapLength\": 6}\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.0.0'></a>\n",
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list below shows all the functions that currently exist in the Python Client for TIM. The way to use each functions is outline in the sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.upload_dataset\n",
    "# client.update_dataset\n",
    "# client.delete_dataset\n",
    "# client.get_datasets\n",
    "# client.get_dataset_versions\n",
    "# client.build_forecasting_model\n",
    "# client.execute_forecast\n",
    "# client.build_forecasting_model_and_execute\n",
    "# client.create_forecast\n",
    "# client.create_forecast_and_execute\n",
    "# client.rebuild_forecasting_model\n",
    "# client.rebuild_forecasting_model_and_execute\n",
    "# client.clean_forecast\n",
    "# client.get_forecast_results\n",
    "# client.get_forecasting_jobs\n",
    "# client.delete_forecast\n",
    "# client.build_anomaly_detection_model\n",
    "# client.execute_anomaly_detection\n",
    "# client.build_anomaly_detection_model_and_execute\n",
    "# client.create_anomaly_detection\n",
    "# client.create_anomaly_detection_and_execute\n",
    "# client.rebuild_anomaly_detection_model\n",
    "# client.rebuild_anomaly_detection_model_and_execute\n",
    "# client.get_anomaly_detection_results\n",
    "# client.get_anomaly_detection_jobs\n",
    "# client.delete_anomaly_detection\n",
    "# client.get_workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.0'></a>\n",
    "## 2.1 Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.1'></a>\n",
    "### 2.1.1. Get Workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract an array with your workspaces already existing in TIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_workspaces_response = client.get_workspaces(offset = 0,\n",
    "                                                limit = 10000,\n",
    "                                                user_group_id = None,\n",
    "                                                sort = '-createdAt'\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Developments',\n",
       " 'userGroup': {'id': '135c50cd-e6ea-423e-ae2b-581564cb9cbc'},\n",
       " 'createdBy': 'd8a49c9e-52ce-4bd5-ab49-eac879005c88',\n",
       " 'isFavorite': True,\n",
       " 'id': 'e3e34c8f-3864-4199-af4b-70366c6a79db',\n",
       " 'createdAt': '2022-04-20T13:22:20.641Z',\n",
       " 'description': ''}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_workspaces_response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_workspaces in module tim.tim:\n",
      "\n",
      "get_workspaces(offset: int = 0, limit: int = 10000, user_group_id: Union[str, NoneType] = None, sort: Union[str, NoneType] = None) -> List[tim.data_sources.workspace.types.Workspace] method of tim.tim.Tim instance\n",
      "    Get a list of workspaces and their metadata\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    offset : int, optional\n",
      "        Number of records to be skipped from beginning of the list, by default 0\n",
      "    limit : int, optional\n",
      "        Maximum number of records to be returned, by default 10000\n",
      "    user_group_id : Optional[str], optional\n",
      "        User Group ID, by default None\n",
      "    sort : Optional[str], optional\n",
      "        Sorting output by the chosen attribute. +/- indicates ascending/descending order, by default -createdAt\n",
      "        Available values : +createdAt, -createdAt, +updatedAt, -updatedAt, +title, -title\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    workspaces : list of Dict\n",
      "        Available keys for each list item (workspace) : id (str), name (str), description (str), userGroup (Dict) with id (str), isFavorite (bool), createdAt (str), createdBy (str), updatedAt (str), updatedBy (str)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.get_workspaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.2'></a>\n",
    "### 2.1.2 Get Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract an array with your datasets already uploaded to TIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_datasets_response = client.get_datasets(offset = None,\n",
    "                                            limit = None,\n",
    "                                            workspace_id = None,\n",
    "                                            sort = None\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'createdAt': '2022-05-05T11:05:37.148Z',\n",
       " 'updatedBy': None,\n",
       " 'estimatedSamplingPeriod': 'P1D',\n",
       " 'name': 'file',\n",
       " 'id': '0dad0b5b-53d8-48d4-9047-aedc2893298b',\n",
       " 'description': '',\n",
       " 'latestVersion': {'numberOfObservations': 990,\n",
       "  'status': 'Finished',\n",
       "  'numberOfVariables': 7,\n",
       "  'id': '289d211b-da5c-49f4-81e7-fe5622abc493',\n",
       "  'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "  'lastTimestamp': '2015-09-17T00:00:00.000Z'},\n",
       " 'createdBy': 'd8a49c9e-52ce-4bd5-ab49-eac879005c88',\n",
       " 'workspace': {'name': 'Default workspace of Philip',\n",
       "  'id': 'bfbeeb15-2f78-48d9-90b0-50bb20789cfe'},\n",
       " 'isFavorite': False,\n",
       " 'updatedAt': None,\n",
       " 'groupKeys': [],\n",
       " 'timeZone': 'Z'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_datasets_response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_datasets in module tim.tim:\n",
      "\n",
      "get_datasets(offset: int = 0, limit: int = 10000, workspace_id: Union[str, NoneType] = None, sort: Union[str, NoneType] = None) -> List[tim.data_sources.dataset.types.Dataset] method of tim.tim.Tim instance\n",
      "    Get a list of datasets and their metadata\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    offset : int, optional\n",
      "        Number of records to be skipped from beginning of the list, by default 0\n",
      "    limit : int, optional\n",
      "        Maximum number of records to be returned, by default 10000\n",
      "    workspace_id : Optional[str] = None\n",
      "        Filter for specific Workspace, by default None\n",
      "    sort : Optional[str] = None\n",
      "        Sorting output by the chosen attribute. +/- indicates ascending/descending order.\n",
      "        Available values : +createdAt, -createdAt\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    datasets : list of Dict\n",
      "        Available keys for each list item (dataset) : id (str), name (str), workspace (Dict), latestVersion (Dict), description (str), isFavorite (bool), estimatedSamplingPeriod (str), createdAt (str), createdBy (str), updatedAt (str), updatedBy (str)\n",
      "        Available keys for workspace are : id (str), name (str)\n",
      "        Available keys for latestVersion are : id (str), status, numberOfVariables (int), numberOfObservations (int), firstTimestamp (str), lastTimestamp (str)\n",
      "        Available values for status are : Registered, Running, Finished, FinishedWithWarning, Failed, Queued\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.get_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.3'></a>\n",
    "### 2.1.3 Get Dataset Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract an array with the versions of your datasets in TIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to run the section \"Get Datasets\" to find a valid dataset id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = get_datasets_response[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_versions_response = client.get_dataset_versions(id = dataset_id,\n",
    "                                                            offset = 0,\n",
    "                                                            limit = 10000\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       " 'createdAt': '2022-05-05T11:05:37.157Z',\n",
       " 'estimatedSamplingPeriod': 'P1D',\n",
       " 'variables': [{'minimumValue': 0.0,\n",
       "   'name': 'Sales',\n",
       "   'maximumValue': 26729.0,\n",
       "   'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "   'lastTimestamp': '2015-07-31T00:00:00.000Z',\n",
       "   'missingObservations': 48,\n",
       "   'type': 'Numerical',\n",
       "   'orderInTable': 2,\n",
       "   'averageValue': 10714.142250530786},\n",
       "  {'minimumValue': 0.0,\n",
       "   'name': 'Customers',\n",
       "   'maximumValue': 2614.0,\n",
       "   'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "   'lastTimestamp': '2015-07-31T00:00:00.000Z',\n",
       "   'missingObservations': 48,\n",
       "   'type': 'Numerical',\n",
       "   'orderInTable': 3,\n",
       "   'averageValue': 1151.3906581740976},\n",
       "  {'minimumValue': 0.0,\n",
       "   'name': 'Open',\n",
       "   'maximumValue': 1.0,\n",
       "   'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "   'lastTimestamp': '2015-09-17T00:00:00.000Z',\n",
       "   'missingObservations': 0,\n",
       "   'type': 'Boolean',\n",
       "   'orderInTable': 4,\n",
       "   'averageValue': 0.8282828282828283},\n",
       "  {'minimumValue': 0.0,\n",
       "   'name': 'Promo',\n",
       "   'maximumValue': 1.0,\n",
       "   'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "   'lastTimestamp': '2015-09-17T00:00:00.000Z',\n",
       "   'missingObservations': 0,\n",
       "   'type': 'Boolean',\n",
       "   'orderInTable': 5,\n",
       "   'averageValue': 0.38282828282828285},\n",
       "  {'minimumValue': 0.0,\n",
       "   'name': 'StateHoliday',\n",
       "   'maximumValue': 1.0,\n",
       "   'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "   'lastTimestamp': '2015-09-17T00:00:00.000Z',\n",
       "   'missingObservations': 0,\n",
       "   'type': 'Boolean',\n",
       "   'orderInTable': 6,\n",
       "   'averageValue': 0.029292929292929294},\n",
       "  {'minimumValue': 0.0,\n",
       "   'name': 'SchoolHoliday',\n",
       "   'maximumValue': 1.0,\n",
       "   'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "   'lastTimestamp': '2015-09-17T00:00:00.000Z',\n",
       "   'missingObservations': 0,\n",
       "   'type': 'Boolean',\n",
       "   'orderInTable': 7,\n",
       "   'averageValue': 0.1787878787878788},\n",
       "  {'minimumValue': 1.0,\n",
       "   'name': 'DayOfWeek',\n",
       "   'maximumValue': 7.0,\n",
       "   'firstTimestamp': '2013-01-01T00:00:00.000Z',\n",
       "   'lastTimestamp': '2015-09-17T00:00:00.000Z',\n",
       "   'missingObservations': 0,\n",
       "   'type': 'Numerical',\n",
       "   'orderInTable': 8,\n",
       "   'averageValue': 3.996969696969697}],\n",
       " 'status': 'Finished',\n",
       " 'numberOfVariables': 7,\n",
       " 'id': '289d211b-da5c-49f4-81e7-fe5622abc493',\n",
       " 'lastTimestamp': '2015-09-17T00:00:00.000Z',\n",
       " 'size': 63360.0,\n",
       " 'dataset': {'id': '0dad0b5b-53d8-48d4-9047-aedc2893298b'},\n",
       " 'numberOfObservations': 990,\n",
       " 'groupKeys': [],\n",
       " 'timeZone': 'Z'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset_versions_response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_dataset_versions in module tim.tim:\n",
      "\n",
      "get_dataset_versions(id: str, offset: int = 0, limit: int = 10000) -> List[tim.data_sources.dataset.types.DatasetListVersion] method of tim.tim.Tim instance\n",
      "    Get a list of the versions of a dataset and their metadata\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    id : str\n",
      "        Dataset ID\n",
      "    offset : int, optional\n",
      "        Number of records to be skipped from beggining of the list, by default 0\n",
      "    limit : int, optional\n",
      "        Maximum number of records to be returned, by default 10000\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    versions : list of Dict\n",
      "        Available keys for each list item (version) : id (str), createdAt (str), status\n",
      "        Available values for status are : Registered, Running, Finished, FinishedWithWarning, Failed, Queued\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.get_dataset_versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.4'></a>\n",
    "### 2.1.4 Get Forecasting Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract an array with previously registered forecasting jobs that are currently available in TIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_forecasting_jobs_response = client.get_forecasting_jobs(offset = 0,\n",
    "                                                            limit = 10000,\n",
    "                                                            sort = '-createdAt',\n",
    "                                                            experiment_id = None,\n",
    "                                                            use_case_id = None,\n",
    "                                                            type = None,\n",
    "                                                            status = None,\n",
    "                                                            parent_id = None,\n",
    "                                                            from_datetime = None,\n",
    "                                                            to_datetime = None\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parentJob': {'id': '8866f771-351d-4ba7-9c76-26481fec6c2e'},\n",
       " 'executedAt': '2022-05-05T12:59:06.588Z',\n",
       " 'createdAt': '2022-05-05T12:59:05.853Z',\n",
       " 'registrationBody': {'configuration': {'predictionTo': {'baseUnit': 'Sample',\n",
       "    'value': 1}}},\n",
       " 'status': 'Finished',\n",
       " 'id': 'a9fec7b7-2074-44cb-aa38-1792dffbe594',\n",
       " 'calculationTime': 'PT0.109S',\n",
       " 'jobLoad': 'Light',\n",
       " 'useCase': {'id': '74c2a27b-8fd0-460f-bea8-ef049a119f51'},\n",
       " 'completedAt': '2022-05-05T12:59:08.952Z',\n",
       " 'errorMeasures': {'bin': [{'name': 'S+1:S+1',\n",
       "    'outOfSample': {'mape': None, 'rmse': None, 'mae': None},\n",
       "    'inSample': {'mape': None, 'rmse': None, 'mae': None}}],\n",
       "  'samplesAhead': [{'name': '1',\n",
       "    'outOfSample': {'mape': None, 'rmse': None, 'mae': None},\n",
       "    'inSample': {'mape': None, 'rmse': None, 'mae': None}}],\n",
       "  'all': {'name': 'all',\n",
       "   'outOfSample': {'mape': None, 'rmse': None, 'mae': None},\n",
       "   'inSample': {'mape': None, 'rmse': None, 'mae': None}}},\n",
       " 'experiment': {'id': '115efc51-5d41-4658-b78d-be5bedb69388'},\n",
       " 'dataset': {'version': {'id': '289d211b-da5c-49f4-81e7-fe5622abc493'}},\n",
       " 'workerVersion': '5.10.0',\n",
       " 'type': 'rebuild-model'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_forecasting_jobs_response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_forecasting_jobs in module tim.tim:\n",
      "\n",
      "get_forecasting_jobs(offset: Union[int, NoneType] = None, limit: Union[int, NoneType] = None, sort: Union[str, NoneType] = None, experiment_id: Union[str, NoneType] = None, use_case_id: Union[str, NoneType] = None, type: Union[str, NoneType] = None, status: Union[str, NoneType] = None, parent_id: Union[str, NoneType] = None, from_datetime: Union[str, NoneType] = None, to_datetime: Union[str, NoneType] = None) -> List[tim.data_sources.forecast.types.ForecastMetadata] method of tim.tim.Tim instance\n",
      "    Get a list of all forecasting jobs and their metadata\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    offset : int, optional\n",
      "        Number of records to be skipped from beggining of the list, by default 0\n",
      "    limit : int, optional\n",
      "        Maximum number of records to be returned, by default 10000\n",
      "    sort : str, optional\n",
      "        Sorting output by the chosen attribute. +/- indicates ascending/descending order, by default '-createdAt'\n",
      "        Available values : +createdAt, -createdAt, +executedAt, -executedAt, +completedAt, -completedAt, +priority, -priority\n",
      "    experiment_id : Optional[str], optional\n",
      "        Filter for a specific Experiment, by default None\n",
      "    use_case_id : Optional[str], optional\n",
      "        Filter for a specific Use Case, by default None\n",
      "    type : Optional[str], optional\n",
      "        Filter for specific types (comma separated string), by default None\n",
      "        Available values : build-model, rebuild-model, predict, rca\n",
      "    status : Optional[str], optional\n",
      "        Filter for specific job statuses (comma separated string), by default None\n",
      "        Available values : Registered, Queued, Running, Finished, FinishedWithWarning, Failed\n",
      "    parent_id : Optional[str], optional\n",
      "        Filter for a specific parent job, by default None\n",
      "    from_datetime : Optional[str], optional\n",
      "        Filter for a minimal date and time of job creation, by default None\n",
      "    to_datetime : Optional[str], optional\n",
      "        Filter for a maximal date and time of job creation, by default None\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    jobs : list of Dict\n",
      "        Available keys for each list item (job) are : id (str), name (str), type (str), status (str), parentJob (Dict), useCase (Dict), experiment (Dict), dataset (Dict), createdAt (str), completedAt (str), executedAt (str), workerVersion (float), jobLoad (str), registrationBody (Dict), errorMeasures (Dict)\n",
      "        Available keys for useCase are : id (str)\n",
      "        Available keys for experiment are: id (str)\n",
      "        Available keys for dataset are : version (Dict) containing id (str)\n",
      "        Available keys for registrationBody are : data (Dict) and configuration (Dict)\n",
      "        Available keys for errorMeasures are : bin (Dict), samplesAhead (Dict), all (Dict)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.get_forecasting_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.5'></a>\n",
    "### 2.1.5 Get Anomaly Detection Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract an array with previously registered anomaly detection jobs that are currently available in TIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomaly_detection_jobs_response = client.get_anomaly_detection_jobs(offset = 0,\n",
    "                                                                        limit = 10000,\n",
    "                                                                        sort = '-createdAt',\n",
    "                                                                        experiment_id = None,\n",
    "                                                                        use_case_id = None,\n",
    "                                                                        type = None,\n",
    "                                                                        status = None,\n",
    "                                                                        parent_id = None,\n",
    "                                                                        from_datetime = None,\n",
    "                                                                        to_datetime = None\n",
    "                                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parentJob': {'id': 'aea7d81c-e319-4f41-bb02-95dd3759945c'},\n",
       " 'executedAt': '2022-05-05T14:42:58.319Z',\n",
       " 'createdAt': '2022-05-05T14:42:57.442Z',\n",
       " 'registrationBody': {},\n",
       " 'name': 'Anomaly Detection rebuild job',\n",
       " 'status': 'FinishedWithWarning',\n",
       " 'id': '70aa01a0-e17f-4f70-a686-c460a6794c77',\n",
       " 'calculationTime': 'PT2.132S',\n",
       " 'jobLoad': 'Light',\n",
       " 'useCase': {'id': '1933d5af-81d6-4b45-9f33-62d2b1fd36bd'},\n",
       " 'completedAt': '2022-05-05T14:43:02.037Z',\n",
       " 'experiment': {'id': '0c0ac0e9-163b-4ad0-8a9e-78655d9950f9'},\n",
       " 'dataset': {'version': {'id': '289d211b-da5c-49f4-81e7-fe5622abc493'}},\n",
       " 'workerVersion': '5.10.0',\n",
       " 'type': 'rebuild-model'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_anomaly_detection_jobs_response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_anomaly_detection_jobs in module tim.tim:\n",
      "\n",
      "get_anomaly_detection_jobs(offset: Union[int, NoneType] = None, limit: Union[int, NoneType] = None, sort: str = '-createdAt', experiment_id: Union[str, NoneType] = None, use_case_id: Union[str, NoneType] = None, type: Union[str, NoneType] = None, status: Union[str, NoneType] = None, parent_id: Union[str, NoneType] = None, from_datetime: Union[str, NoneType] = None, to_datetime: Union[str, NoneType] = None) -> List[tim.data_sources.anomaly_detection.types.AnomalyDetection] method of tim.tim.Tim instance\n",
      "    Get a list of all anomaly detection jobs and their metadata\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    offset : int, optional\n",
      "        Number of records to be skipped from beginning of the list, by default 0\n",
      "    limit : int, optional\n",
      "        Maximum number of records to be returned, by default 100\n",
      "    sort : str, optional\n",
      "        Sorting output by the chosen attribute. +/- indicates ascending/descending order, by default '-createdAt'\n",
      "        Available values : +createdAt, -createdAt, +executedAt, -executedAt, +completedAt, -completedAt, +priority, -priority\n",
      "    experiment_id : Optional[str], optional\n",
      "        Filter for a specific Experiment, by default None\n",
      "    use_case_id : Optional[str], optional\n",
      "        Filter for a specific Use Case, by default None\n",
      "    type : Optional[str], optional\n",
      "        Filter for specific types (comma separated string), by default None\n",
      "        Available values : build-model, rebuild-model, detect, rca\n",
      "    status : Optional[str], optional\n",
      "        Filter for specific job statuses (comma separated string), by default None\n",
      "        Available values : Registered, Queued, Running, Finished, FinishedWithWarning, Failed\n",
      "    parent_id : Optional[str], optional\n",
      "        Filter for a specific parent job, by default None\n",
      "    from_datetime : Optional[str], optional\n",
      "        Filter for a minimal date and time of job creation, by default None\n",
      "    to_datetime : Optional[str], optional\n",
      "        Filter for a maximal date and time of job creation, by default None\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    jobs : list of Dict\n",
      "        Available keys for each list item (job) are : id (str), name (str), type (str), status (str), parentJob (Dict), useCase (Dict), experiment (Dict), dataset (Dict), createdAt (str), completedAt (str), executedAt (str), workerVersion (float), registrationBody (Dict)\n",
      "        Available keys for registrationBody are : name (str), useCase (Dict), data (Dict), configuration (Dict)\n",
      "        Available keys for useCase are : id (str)\n",
      "        Available keys for experiment are: id (str)\n",
      "        Available keys for dataset are : version (Dict) containing id (str)\n",
      "        Available keys for registrationBody are : data (Dict) and configuration (Dict)\n",
      "        Available keys for errorMeasures are : bin (Dict), samplesAhead (Dict), all (Dict)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.get_anomaly_detection_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2.0'></a>\n",
    "## 2.2 Dataset Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2.1'></a>\n",
    "### 2.2.1 Upload Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload a new dataset to TIM using a pandas dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Finished', 'progress': 100.0, 'createdAt': '2022-05-06T11:47:52.203Z'}\n"
     ]
    }
   ],
   "source": [
    "upload_dataset_response = client.upload_dataset(dataset = tim_input_df,\n",
    "                                                configuration = dataset_configuration,\n",
    "                                                wait_to_finish = True,\n",
    "                                                handle_status_poll = print\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata = upload_dataset_response[0]\n",
    "logs = upload_dataset_response[1]\n",
    "\n",
    "dataset_id = dataset_metadata['id']\n",
    "dataset_version_id = dataset_metadata['latestVersion']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method upload_dataset in module tim.tim:\n",
      "\n",
      "upload_dataset(dataset: pandas.core.frame.DataFrame, configuration: tim.data_sources.dataset.types.UploadDatasetConfiguration = {}, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.data_sources.dataset.types.DatasetStatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.dataset.types.UploadDatasetResultsResponse, tim.data_sources.dataset.types.UploadDatasetResponse] method of tim.tim.Tim instance\n",
      "    Upload a dataset to the TIM repository\n",
      "    \n",
      "      Parameters\n",
      "      ----------\n",
      "      dataset : DataFrame\n",
      "              The dataset containing time-series data\n",
      "      configuration: Dict\n",
      "              Metadata of the dataset, Optional\n",
      "        Available keys are: timestampFormat, timestampColumn, decimalSeparator, name, description and samplingPeriod\n",
      "              The value of samplingPeriod is a Dict containing the keys baseUnit and value\n",
      "    wait_to_finish : bool, Optional\n",
      "      Wait for the dataset to be uploaded before returning\n",
      "      If set to False, the function will return once the dataset upload process has started\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the dataset upload\n",
      "    \n",
      "      Returns\n",
      "      -------\n",
      "      dataset_metadata : Dict | None\n",
      "              Dict when successful; None when unsuccessful\n",
      "      logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.upload_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2.2'></a>\n",
    "### 2.2.2 Delete Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete a previously uploaded dataset from TIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid dataset_id for example by running the \"Upload Dataset\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_dataset_response = client.delete_dataset(dataset_id=dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Dataset with ID 1e455442-ac10-4f16-8565-d8a864238683 successfully deleted.',\n",
       " 'code': 'DM09038'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_dataset_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method delete_dataset in module tim.tim:\n",
      "\n",
      "delete_dataset(dataset_id: str) -> tim.types.ExecuteResponse method of tim.tim.Tim instance\n",
      "    Delete a dataset\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_id : str\n",
      "        ID of the dataset to delete\n",
      "    Returns\n",
      "    -------\n",
      "    message : Dict\n",
      "        Available keys: message (str) and code (str)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.delete_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2.3'></a>\n",
    "### 2.2.3 Update Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update a previously uploaded dataset in TIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid dataset_id for example by running the \"Upload Dataset\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Finished', 'progress': 100.0, 'createdAt': '2022-05-06T11:48:13.866Z'}\n"
     ]
    }
   ],
   "source": [
    "update_dataset_response = client.update_dataset(dataset_id = dataset_id,\n",
    "                                                dataset_version = update_df,\n",
    "                                                configuration = update_dataset_configuration,\n",
    "                                                wait_to_finish = True,\n",
    "                                                handle_status_poll = print\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata = update_dataset_response[0]\n",
    "logs = update_dataset_response[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method update_dataset in module tim.tim:\n",
      "\n",
      "update_dataset(dataset_id: str, dataset_version: pandas.core.frame.DataFrame, configuration: tim.data_sources.dataset.types.UpdateDatasetConfiguration = {}, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.data_sources.dataset.types.DatasetStatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.dataset.types.UploadDatasetResultsResponse, tim.data_sources.dataset.types.UpdateDatasetResponse] method of tim.tim.Tim instance\n",
      "    Update a dataset in the TIM repository by uploading a new version\n",
      "    \n",
      "      Parameters\n",
      "      ----------\n",
      "      dataset_id: str\n",
      "        The ID of the dataset to update\n",
      "      dataset_version : DataFrame\n",
      "              The dataset containing time-series data\n",
      "      configuration: Dict\n",
      "              Metadata of the dataset, Optional\n",
      "        Available keys are: timestampFormat, timestampColumn, decimalSeparator\n",
      "    wait_to_finish : bool, Optional\n",
      "      Wait for the dataset version to be uploaded before returning\n",
      "      If set to False, the function will return once the dataset version upload process has started\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the dataset version upload\n",
      "    \n",
      "      Returns\n",
      "      -------\n",
      "      dataset_metadata : Dict | None\n",
      "              Dict when successful; None when unsuccessful\n",
      "      logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.update_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.0'></a>\n",
    "## 2.3 Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.1'></a>\n",
    "### 2.3.1 Build Forecasting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register a forecasting job of the type: build-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid dataset_id for example by running the \"Upload Dataset\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_forecasting_model_response = client.build_forecasting_model(dataset_id = dataset_id,\n",
    "                                                                  job_configuration = forecast_build_model_configuration\n",
    "                                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8ae40ae6-41d9-4c96-9b41-e641cf38078e'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_forecasting_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method build_forecasting_model in module tim.tim:\n",
      "\n",
      "build_forecasting_model(dataset_id: str, job_configuration: Union[tim.data_sources.forecast.types.BuildForecastingModelConfiguration, NoneType] = None) -> str method of tim.tim.Tim instance\n",
      "    Create a forecast job in the workspace the dataset is connected to (the default workspace)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_id : str\n",
      "        The ID of a dataset in the TIM repository\n",
      "    job_configuration : BuildForecastingModelConfiguration, Optional\n",
      "        TIM Engine model building and forecasting configuration, by default None\n",
      "        Available keys are: name, configuration, data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    id : str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.build_forecasting_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.2'></a>\n",
    "### 2.3.2 Execute Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a registered forecasting job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to first run the section \"Build Forecasting Model\" and send through a job_id that hasn't been executed jet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'createdAt': '2022-05-05T16:47:01.123Z'}\n",
      "{'status': 'Running', 'progress': 46.06, 'CPU': 0.94, 'memory': 10.92, 'createdAt': '2022-05-05T16:47:13.186Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.94, 'memory': 10.91, 'createdAt': '2022-05-05T16:47:15.793Z'}\n"
     ]
    }
   ],
   "source": [
    "execute_forecast_response = client.execute_forecast(forecast_job_id = build_forecasting_model_response,\n",
    "                                                    wait_to_finish = True,\n",
    "                                                    handle_status_poll = print\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = execute_forecast_response[0]\n",
    "model_result = execute_forecast_response[1]\n",
    "table_result = execute_forecast_response[2]\n",
    "accuarcies = execute_forecast_response[3]\n",
    "logs = execute_forecast_response[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method execute_forecast in module tim.tim:\n",
      "\n",
      "execute_forecast(forecast_job_id: str, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.forecast.types.ForecastResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Execute a forecast job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    forecast_job_id : str\n",
      "        The ID of a forecast job to execute\n",
      "    wait_to_finish : bool, Optional\n",
      "        Wait for all results to be calculated before returning\n",
      "        If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the forecasting job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    accuracies : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.execute_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wait_to_finish is set to false, TIM will respond with the message that your request is being processed. You can now proceed with other processes without having to wait for the result to be sent back from TIM. The results can be extract after the job is finished using the client.get_forecast_results function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_forecast_response = client.execute_forecast(forecast_job_id=build_forecasting_model_response,wait_to_finish=False,handle_status_poll=print)\n",
    "# execute_forecast_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.3'></a>\n",
    "### 2.3.3 Build Forecasting Model & Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and execute a forecasting job of the type: build-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid dataset_id for example by running the \"Upload Dataset\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'progress': 20.6, 'CPU': 0.19, 'memory': 10.93, 'createdAt': '2022-05-06T09:05:28.094Z'}\n",
      "{'status': 'Running', 'progress': 54.54, 'CPU': 0.19, 'memory': 10.91, 'createdAt': '2022-05-06T09:05:30.400Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.58, 'memory': 10.91, 'createdAt': '2022-05-06T09:05:32.399Z'}\n"
     ]
    }
   ],
   "source": [
    "build_forecasting_model_and_execute_response = client.build_forecasting_model_and_execute(dataset_id = dataset_id,\n",
    "                                                                                          job_configuration = forecast_build_model_configuration,\n",
    "                                                                                          wait_to_finish = True,\n",
    "                                                                                          handle_status_poll = print\n",
    "                                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = build_forecasting_model_and_execute_response[0]\n",
    "model_result = build_forecasting_model_and_execute_response[1]\n",
    "table_result = build_forecasting_model_and_execute_response[2]\n",
    "accuarcies = build_forecasting_model_and_execute_response[3]\n",
    "logs = build_forecasting_model_and_execute_response[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method build_forecasting_model_and_execute in module tim.tim:\n",
      "\n",
      "build_forecasting_model_and_execute(dataset_id: str, job_configuration: Union[tim.data_sources.forecast.types.BuildForecastingModelConfiguration, NoneType] = None, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.forecast.types.ForecastResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Create a forecast job in the workspace the dataset is connected to (default workspace) and execute it\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_id : str\n",
      "      The ID of a dataset in the TIM repository\n",
      "    job_configuration : BuildForecastingModelConfiguration\n",
      "      TIM Engine model building and forecasting configuration\n",
      "      Available keys are : name, configuration, data\n",
      "    wait_to_finish : bool, Optional\n",
      "      Wait for all results to be calculated before returning\n",
      "      If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the forecasting job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    accuracies : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.build_forecasting_model_and_execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wait_to_finish is set to false, TIM will respond with the message that your request is being processed. You can proceed with other processes without having to wait for the result to be sent back from TIM. You can extract the results after the job is finished using the client.get_forecast_results function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_forecasting_model_and_execute_response = client.build_forecasting_model_and_execute(dataset_id = dataset_id,\n",
    "                                                                                          job_configuration = forecast_build_model_configuration,\n",
    "                                                                                          wait_to_finish = False,\n",
    "                                                                                          handle_status_poll = print\n",
    "                                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Forecast job b379964d-a225-4f7a-8962-c0106419bfad has been posted to queue.',\n",
       " 'code': 'JM09020'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_forecasting_model_and_execute_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.4'></a>\n",
    "### 2.3.4 Create Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register a forecasting job of the type: predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Forecasting Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_forecast_response = client.create_forecast(parent_job_id = build_forecasting_model_response,\n",
    "                                                  job_configuration = forecast_predict_configuration\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bc80fba7-e3cf-40c6-bdd0-54cdd951908d'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_forecast_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_forecast in module tim.tim:\n",
      "\n",
      "create_forecast(parent_job_id: str, job_configuration: Union[tim.data_sources.forecast.types.ForecastingPredictConfiguration, NoneType] = None) -> str method of tim.tim.Tim instance\n",
      "    Create a forecasting job using the same model as the parent forecasting job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "      The ID of a parent forecasting job\n",
      "    job_configuration : ForecastingPredictConfiguration\n",
      "      TIM Engine forecasting configuration\n",
      "      Available keys are : name, configuration, data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    id : str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.create_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.5'></a>\n",
    "### 2.3.5 Create Forecast & Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and execute a forecasting job of the type: predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Forecasting Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'createdAt': '2022-05-05T16:51:55.839Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.28, 'memory': 10.93, 'createdAt': '2022-05-05T16:51:58.786Z'}\n"
     ]
    }
   ],
   "source": [
    "create_forecast_and_execute_response = client.create_forecast_and_execute(parent_job_id = build_forecasting_model_response,\n",
    "                                                                          job_configuration = forecast_predict_configuration,\n",
    "                                                                          wait_to_finish = True,\n",
    "                                                                          handle_status_poll = print\n",
    "                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = create_forecast_and_execute_response[0]\n",
    "model_result = create_forecast_and_execute_response[1]\n",
    "table_result = create_forecast_and_execute_response[2]\n",
    "accuarcies = create_forecast_and_execute_response[3]\n",
    "logs = create_forecast_and_execute_response[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_forecast_and_execute in module tim.tim:\n",
      "\n",
      "create_forecast_and_execute(parent_job_id: str, job_configuration: Union[tim.data_sources.forecast.types.ForecastingPredictConfiguration, NoneType] = None, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.forecast.types.ForecastResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Create a forecasting job using the same model as the parent forecasting job and execute it\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "        The ID of a parent forecasting job\n",
      "    job_configuration : ForecastingPredictConfiguration\n",
      "        TIM Engine forecasting configuration\n",
      "        Available keys are : name, configuration, data\n",
      "    wait_to_finish : bool, Optional\n",
      "        Wait for all results to be calculated before returning\n",
      "        If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "        A callback function to poll for the status and progress of the forecasting job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "        Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "        Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "        DataFrame when successful; None when unsuccessful\n",
      "    accuracies : Dict | None\n",
      "        Dict when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.create_forecast_and_execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.6'></a>\n",
    "### 2.3.6 Rebuild Forecasting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and a forecasting job of the type: rebuild-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Forecasting Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuild_forecasting_model_response = client.rebuild_forecasting_model(parent_job_id = build_forecasting_model_response,\n",
    "                                                                      job_configuration = forecast_rebuild_configuration\n",
    "                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'912c2f36-3d1a-461b-b089-b9fdfa92e0d7'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuild_forecasting_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method rebuild_forecasting_model in module tim.tim:\n",
      "\n",
      "rebuild_forecasting_model(parent_job_id: str, job_configuration: Union[tim.data_sources.forecast.types.ForecastingRebuildModelConfiguration, NoneType] = None) -> str method of tim.tim.Tim instance\n",
      "    Create a forecast job to rebuild the model(s) of the parent forecasting job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "        The ID of a parent forecasting job\n",
      "    job_configuration : ForecastingRebuildModelConfiguration, Optional\n",
      "        TIM Engine model rebuilding and forecasting configuration, by default None\n",
      "        Available keys are: name, configuration, data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    id : str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.rebuild_forecasting_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.7'></a>\n",
    "### 2.3.7 Rebuild Forecasting Model & Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and execute a forecasting job of the type: rebuild-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Forecasting Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'createdAt': '2022-05-05T16:52:38.351Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.13, 'memory': 10.93, 'createdAt': '2022-05-05T16:52:41.425Z'}\n"
     ]
    }
   ],
   "source": [
    "rebuild_forecasting_model_and_execute_response = client.rebuild_forecasting_model_and_execute(parent_job_id = build_forecasting_model_response,\n",
    "                                                                                              job_configuration = forecast_rebuild_configuration,\n",
    "                                                                                              wait_to_finish = True,\n",
    "                                                                                              handle_status_poll = print\n",
    "                                                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = create_forecast_and_execute_response[0]\n",
    "model_result = create_forecast_and_execute_response[1]\n",
    "table_result = create_forecast_and_execute_response[2]\n",
    "accuarcies = create_forecast_and_execute_response[3]\n",
    "logs = create_forecast_and_execute_response[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method rebuild_forecasting_model_and_execute in module tim.tim:\n",
      "\n",
      "rebuild_forecasting_model_and_execute(parent_job_id: str, job_configuration: Union[tim.data_sources.forecast.types.ForecastingRebuildModelConfiguration, NoneType] = None, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.forecast.types.ForecastResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Create a forecast job to rebuild the model(s) of the parent forecasting job and execute it\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "        The ID of a parent forecasting job\n",
      "    job_configuration : ForecastingRebuildModelConfiguration, Optional\n",
      "        TIM Engine model rebuilding and forecasting configuration, by default None\n",
      "        Available keys are: name, configuration, data\n",
      "    wait_to_finish : bool, Optional\n",
      "      Wait for all results to be calculated before returning\n",
      "      If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the forecasting job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    accuracies : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.rebuild_forecasting_model_and_execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.8'></a>\n",
    "### 2.3.8 Clean Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload a dataset, register a forecasting job, execute that job, extract all results from TIM and delete all information from TIM in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Finished', 'progress': 100.0, 'createdAt': '2022-05-05T16:52:57.403Z'}\n",
      "{'status': 'Running', 'createdAt': '2022-05-05T16:53:02.461Z'}\n",
      "{'status': 'Running', 'progress': 54.54, 'CPU': 0.15, 'memory': 10.91, 'createdAt': '2022-05-05T16:53:07.516Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.46, 'memory': 10.93, 'createdAt': '2022-05-05T16:53:09.501Z'}\n"
     ]
    }
   ],
   "source": [
    "clean_forecast_response = client.clean_forecast(dataset = tim_input_df,\n",
    "                                                dataset_configuration = dataset_configuration,\n",
    "                                                job_configuration = forecast_build_model_configuration,\n",
    "                                                handle_dataset_upload_status_poll = print,\n",
    "                                                handle_forecast_status_poll = print\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = clean_forecast_response[0]\n",
    "model_result = clean_forecast_response[1]\n",
    "table_result = clean_forecast_response[2]\n",
    "accuarcies = clean_forecast_response[3]\n",
    "forecasting_logs = clean_forecast_response[4]\n",
    "dataset_logs = clean_forecast_response[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method clean_forecast in module tim.tim:\n",
      "\n",
      "clean_forecast(dataset: pandas.core.frame.DataFrame, dataset_configuration: tim.data_sources.dataset.types.UploadCSVConfiguration = {}, job_configuration: Union[tim.data_sources.forecast.types.BuildForecastingModelConfiguration, NoneType] = None, handle_dataset_upload_status_poll: Union[Callable[[tim.data_sources.dataset.types.DatasetStatusResponse], NoneType], NoneType] = None, handle_forecast_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.forecast.types.CleanForecastResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Perform a clean forecast: upload the dataset in the default workspace, create a forecast job in this workspace, execute it, return the results and delete the dataset and job from the TIM Repository\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset : DataFrame\n",
      "      The dataset containing time-series data\n",
      "    dataset_configuration: Dict\n",
      "      Metadata of the dataset, Optional\n",
      "      Available keys are: timestampFormat, timestampColumn, decimalSeparator, name, description and samplingPeriod\n",
      "      The value of samplingPeriod is a Dict containing the keys baseUnit and value\n",
      "    job_configuration : BuildForecastingModelConfiguration\n",
      "      TIM Engine model building and forecasting configuration\n",
      "      Available keys are : name, configuration, data\n",
      "    handle_dataset_upload_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the dataset upload\n",
      "    handle_forecast_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the forecasting job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    accuracies : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    forecasting_logs : list of Dict\n",
      "    dataset_logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.clean_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.9'></a>\n",
    "### 2.3.9 Get Forecast Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract results from a forecasting job from TIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid job_id from an executed job for example by running the \"Build Forecasting Model\" & the \"Execute Forecast\" sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_forecast_results_response = client.get_forecast_results(forecast_job_id = build_forecasting_model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = get_forecast_results_response[0]\n",
    "model_result = get_forecast_results_response[1]\n",
    "table_result = get_forecast_results_response[2]\n",
    "accuarcies = get_forecast_results_response[3]\n",
    "logs = get_forecast_results_response[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_forecast_results in module tim.tim:\n",
      "\n",
      "get_forecast_results(forecast_job_id: str) -> tim.data_sources.forecast.types.ForecastResultsResponse method of tim.tim.Tim instance\n",
      "    Retrieve the results of a forecast job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    forecast_job_id : str\n",
      "      The ID of a forecast job\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    accuracies : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.get_forecast_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3.10'></a>\n",
    "### 2.3.10 Delete Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete and/or stop a forecasting job that exists in TIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid job_id from an executed job for example by running the \"Create Forecasting\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_forecast_response = client.delete_forecast(forecast_job_id = create_forecast_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Forecast job bc80fba7-e3cf-40c6-bdd0-54cdd951908d successfully stopped and deleted.',\n",
       " 'code': 'JM07027'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_forecast_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method delete_forecast in module tim.tim:\n",
      "\n",
      "delete_forecast(forecast_job_id: str) -> tim.types.ExecuteResponse method of tim.tim.Tim instance\n",
      "    Delete a forecasting job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    forecast_job_id : str\n",
      "        ID of the forecasting job to delete\n",
      "    Returns\n",
      "    -------\n",
      "    message : Dict\n",
      "        Available keys: message (str) and code (str)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.delete_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.0'></a>\n",
    "## 2.4 Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.1'></a>\n",
    "### 2.4.1 Build Anomaly Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register an anomaly detection job of the type: build-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid dataset_id for example by running the \"Upload Dataset\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_anomaly_detection_model_response = client.build_anomaly_detection_model(dataset_id = dataset_id,\n",
    "                                                                              job_configuration = detection_build_model_configuration\n",
    "                                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88490281-fed5-44b2-b4cb-0ec6f41c8be5'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_anomaly_detection_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method build_anomaly_detection_model in module tim.tim:\n",
      "\n",
      "build_anomaly_detection_model(dataset_id: str, job_configuration: Union[tim.data_sources.anomaly_detection.types.BuildAnomalyDetectionModelConfiguration, NoneType] = None) -> str method of tim.tim.Tim instance\n",
      "    Create an anomaly detection job in the workspace the dataset is connected to (default workspace)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_id : str\n",
      "      The ID of a dataset in the TIM repository\n",
      "    job_configuration : BuildAnomalyDetectionModelConfiguration\n",
      "      TIM Engine model building and anomaly detection configuration\n",
      "      Available keys are : name, configuration, data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    id : str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.build_anomaly_detection_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.2'></a>\n",
    "### 2.4.2 Execute Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a registered anomaly detection job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to first run the section \"Build Anomaly Detection Model\" and send through a job_id that hasn't been executed jet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'progress': 6.5, 'CPU': 0.17, 'memory': 10.91, 'createdAt': '2022-05-05T16:57:57.617Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.32, 'memory': 10.93, 'createdAt': '2022-05-05T16:57:59.292Z'}\n"
     ]
    }
   ],
   "source": [
    "execute_anomaly_detection_response = client.execute_anomaly_detection(anomaly_detection_job_id = build_anomaly_detection_model_response,\n",
    "                                                                      wait_to_finish = True,\n",
    "                                                                      handle_status_poll = print\n",
    "                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = execute_anomaly_detection_response[0]\n",
    "model_result = execute_anomaly_detection_response[1]\n",
    "table_result = execute_anomaly_detection_response[2]\n",
    "logs = execute_anomaly_detection_response[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method execute_anomaly_detection in module tim.tim:\n",
      "\n",
      "execute_anomaly_detection(anomaly_detection_job_id: str, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Execute an anomaly detection job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    anomaly_detection_job_id : str\n",
      "        The ID of an anomaly detection job to execute\n",
      "    wait_to_finish : bool, Optional\n",
      "        Wait for all results to be calculated before returning\n",
      "        If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the anomaly detection job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.execute_anomaly_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.3'></a>\n",
    "### 2.4.3 Build Anomaly Detection Model & Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and execute an anomaly detection job of the type: build-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid dataset_id for example by running the \"Upload Dataset\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'progress': 5.0, 'CPU': 0.21, 'memory': 10.91, 'createdAt': '2022-05-05T16:58:29.138Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.19, 'memory': 10.94, 'createdAt': '2022-05-05T16:58:30.772Z'}\n"
     ]
    }
   ],
   "source": [
    "build_anomaly_detection_model_and_execute_response = client.build_anomaly_detection_model_and_execute(dataset_id = dataset_id,\n",
    "                                                                                                      job_configuration = detection_build_model_configuration,\n",
    "                                                                                                      wait_to_finish = True,\n",
    "                                                                                                      handle_status_poll = print\n",
    "                                                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = build_anomaly_detection_model_and_execute_response[0]\n",
    "model_result = build_anomaly_detection_model_and_execute_response[1]\n",
    "table_result = build_anomaly_detection_model_and_execute_response[2]\n",
    "logs = build_anomaly_detection_model_and_execute_response[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method build_anomaly_detection_model_and_execute in module tim.tim:\n",
      "\n",
      "build_anomaly_detection_model_and_execute(dataset_id: str, job_configuration: Union[tim.data_sources.anomaly_detection.types.BuildAnomalyDetectionModelConfiguration, NoneType] = None, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Create an anomaly detection job in the workspace the dataset is connected to (default workspace) and execute it\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_id : str\n",
      "      The ID of a dataset in the TIM repository\n",
      "    job_configuration : BuildAnomalyDetectionModelConfiguration\n",
      "      TIM Engine model building and anomaly detection configuration\n",
      "      Available keys are : name, configuration, data\n",
      "    wait_to_finish : bool, Optional\n",
      "      Wait for all results to be calculated before returning\n",
      "      If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the anomaly detection job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.build_anomaly_detection_model_and_execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.4'></a>\n",
    "### 2.4.4 Create Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register an anomaly detection job of the type: detect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Anomaly Detection Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_anomaly_detection_response = client.create_anomaly_detection(parent_job_id = build_anomaly_detection_model_response,\n",
    "                                                                    job_configuration = detection_detect_configuration\n",
    "                                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d6502159-c99b-41d0-a5d5-e055925ee6de'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_anomaly_detection_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_anomaly_detection in module tim.tim:\n",
      "\n",
      "create_anomaly_detection(parent_job_id: str, job_configuration: Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionDetectConfiguration, NoneType] = None) -> str method of tim.tim.Tim instance\n",
      "    Create an anomaly detection job using the same model as the parent anomaly detection job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "      The ID of a parent anomaly detection job\n",
      "    job_configuration : AnomalyDetectionDetectConfiguration\n",
      "      TIM Engine anomaly detection configuration\n",
      "      Available keys are : name, data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    id : str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.create_anomaly_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.5'></a>\n",
    "### 2.4.5 Create Anomaly Detection & Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and execute an anomaly detection job of the type: detect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Anomaly Detection Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'progress': 24.0, 'CPU': 0.12, 'memory': 10.91, 'createdAt': '2022-05-05T17:00:00.343Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'CPU': 0.12, 'memory': 10.91, 'createdAt': '2022-05-05T17:00:00.899Z'}\n"
     ]
    }
   ],
   "source": [
    "create_anomaly_detection_and_execute_response = client.create_anomaly_detection_and_execute(parent_job_id = build_anomaly_detection_model_response,\n",
    "                                                                                            job_configuration = detection_detect_configuration,\n",
    "                                                                                            wait_to_finish = True,\n",
    "                                                                                            handle_status_poll = print\n",
    "                                                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = create_anomaly_detection_and_execute_response[0]\n",
    "model_result = create_anomaly_detection_and_execute_response[1]\n",
    "table_result = create_anomaly_detection_and_execute_response[2]\n",
    "logs = create_anomaly_detection_and_execute_response[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_anomaly_detection_and_execute in module tim.tim:\n",
      "\n",
      "create_anomaly_detection_and_execute(parent_job_id: str, job_configuration: Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionDetectConfiguration, NoneType] = None, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Create an anomaly detection job using the same model as the parent anomaly detection job and execute it\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "      The ID of a parent anomaly detection job\n",
      "    job_configuration : AnomalyDetectionDetectConfiguration\n",
      "      TIM Engine anomaly detection configuration\n",
      "      Available keys are : name, data\n",
      "    wait_to_finish : bool, Optional\n",
      "      Wait for all results to be calculated before returning\n",
      "      If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the anomaly detection job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.create_anomaly_detection_and_execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.6'></a>\n",
    "### 2.4.6 Rebuild Anomaly Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and an anomaly detection job of the type: rebuild-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Anomaly Detection Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuild_anomaly_detection_model_response = client.rebuild_anomaly_detection_model(parent_job_id = build_anomaly_detection_model_response,\n",
    "                                                                                  job_configuration = detection_rebuild_configuration\n",
    "                                                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65f81ba1-bc44-4b03-8e15-c5c9fb589046'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuild_anomaly_detection_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method rebuild_anomaly_detection_model in module tim.tim:\n",
      "\n",
      "rebuild_anomaly_detection_model(parent_job_id: str, job_configuration: Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionRebuildModelConfiguration, NoneType] = None) -> str method of tim.tim.Tim instance\n",
      "    Create an anomaly detection job to rebuild the model(s) of the parent anomaly detection job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "        The ID of a parent anomaly detection job\n",
      "    job_configuration : AnomalyDetectionRebuildModelConfiguration, Optional\n",
      "        TIM Engine model rebuilding and detection configuration, by default None\n",
      "        Available keys are: name, configuration, data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    id : str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.rebuild_anomaly_detection_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.7'></a>\n",
    "### 2.4.7 Rebuild Anomaly Detection Model & Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register and execute an anomaly detection job of the type: rebuild-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid parent_job_id for example by running the \"Build Anomaly Detection Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'progress': 4.0, 'CPU': 0.1, 'memory': 10.91, 'createdAt': '2022-05-05T17:00:45.196Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'CPU': 0.1, 'memory': 10.93, 'createdAt': '2022-05-05T17:00:46.882Z'}\n"
     ]
    }
   ],
   "source": [
    "rebuild_anomaly_detection_model_and_execute_response = client.rebuild_anomaly_detection_model_and_execute(parent_job_id = build_anomaly_detection_model_response,\n",
    "                                                                                                          job_configuration = detection_rebuild_configuration,\n",
    "                                                                                                          wait_to_finish = True,\n",
    "                                                                                                          handle_status_poll = print\n",
    "                                                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = rebuild_anomaly_detection_model_and_execute_response[0]\n",
    "model_result = rebuild_anomaly_detection_model_and_execute_response[1]\n",
    "table_result = rebuild_anomaly_detection_model_and_execute_response[2]\n",
    "logs = rebuild_anomaly_detection_model_and_execute_response[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method rebuild_anomaly_detection_model_and_execute in module tim.tim:\n",
      "\n",
      "rebuild_anomaly_detection_model_and_execute(parent_job_id: str, job_configuration: Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionRebuildModelConfiguration, NoneType] = None, wait_to_finish: bool = True, handle_status_poll: Union[Callable[[tim.types.StatusResponse], NoneType], NoneType] = None) -> Union[tim.data_sources.anomaly_detection.types.AnomalyDetectionResultsResponse, tim.types.ExecuteResponse] method of tim.tim.Tim instance\n",
      "    Create an anomaly detection job to rebuild the model(s) of the parent anomaly detection job and execute it\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    parent_job_id : str\n",
      "        The ID of a parent anomaly detection job\n",
      "    job_configuration : AnomalyDetectionRebuildModelConfiguration, Optional\n",
      "        TIM Engine model rebuilding and anomaly detection configuration, by default None\n",
      "        Available keys are: name, configuration, data\n",
      "    wait_to_finish : bool, Optional\n",
      "      Wait for all results to be calculated before returning\n",
      "      If set to False, the function will return once the job has started the execution process\n",
      "    handle_status_poll: Callable, Optional\n",
      "      A callback function to poll for the status and progress of the anomaly detection job execution\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      DataFrame when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.rebuild_anomaly_detection_model_and_execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.8'></a>\n",
    "### 2.4.8 Get Anomaly Detection Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract results from an anomaly detection job from TIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid job_id from an executed job for example by running the \"Build Anomaly Detection Model\" & the \"Execute Anomaly Detection\" sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_anomaly_detection_results_response = client.get_anomaly_detection_results(anomaly_detection_job_id = build_anomaly_detection_model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = get_anomaly_detection_results_response[0]\n",
    "model_result = get_anomaly_detection_results_response[1]\n",
    "table_result = get_anomaly_detection_results_response[2]\n",
    "logs = get_anomaly_detection_results_response[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_anomaly_detection_results in module tim.tim:\n",
      "\n",
      "get_anomaly_detection_results(anomaly_detection_job_id: str) -> tim.data_sources.anomaly_detection.types.AnomalyDetectionResultsResponse method of tim.tim.Tim instance\n",
      "    Retrieve the results of an anomaly detection job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    anomaly_detection_job_id : str\n",
      "        The ID of an anomaly detection job\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    metadata : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    model_result : Dict | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    table_result : DataFrame | None\n",
      "      Dict when successful; None when unsuccessful\n",
      "    logs : list of Dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.get_anomaly_detection_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4.9'></a>\n",
    "### 2.4.9 Delete Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete and/or stop an anomaly detection job that exists in TIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to have a valid job_id from an executed job for example by running the \"Create Anomaly Detection\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_anomaly_detection_response = client.delete_anomaly_detection(anomaly_detection_job_id = create_anomaly_detection_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Anomaly Detection job d6502159-c99b-41d0-a5d5-e055925ee6de successfully stopped and deleted.',\n",
       " 'code': 'JM31073'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_anomaly_detection_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method delete_anomaly_detection in module tim.tim:\n",
      "\n",
      "delete_anomaly_detection(anomaly_detection_job_id: str) -> tim.types.ExecuteResponse method of tim.tim.Tim instance\n",
      "    Delete an anomaly detection job\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    anomaly_detection_job_id : str\n",
      "        ID of the anomaly detection job to delete\n",
      "    Returns\n",
      "    -------\n",
      "    message : Dict\n",
      "        Available keys: message (str) and code (str)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.delete_anomaly_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Overview](#Overview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
