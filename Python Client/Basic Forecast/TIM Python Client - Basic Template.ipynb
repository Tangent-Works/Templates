{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------- TIM Python Client - Basic Template -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "Import the libraries necessary to run this notebook and set up the python client for TIM.\n",
    "Make sure to fill in your credentials for TIM in the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tim import Tim\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_credentials = json.load(open('tim_credentials.json'))\n",
    "client = Tim(email=tim_credentials['email'],password=tim_credentials['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "In this example we use the Belgian Electricity Grid dataset which is already preprocessed for use with TIM.\n",
    "The dataframe tim_input_df is what will eventually be sent to TIM. If you wish to adapt this file you can apply the necessary transformations here.\n",
    "The final dataframe is then visualized below in both a graph and a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv('Belgian Electricity Grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_input_df = csv_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = 'Timestamp'\n",
    "target_variable = 'Quantity'\n",
    "predictor_candidates = [s for s in list(tim_input_df.columns) if s not in [timestamp,target_variable]]\n",
    "tim_input_df = tim_input_df[[timestamp,target_variable]+predictor_candidates].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = tim_input_df\n",
    "fig = plt.subplots.make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[target_variable], name=target_variable), row=1, col=1)\n",
    "for idx, p in enumerate(predictor_candidates):\n",
    "    fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[p], name=p), row=2, col=1)\n",
    "fig.update_layout(height=600, width=1200, title_text=\"Data visualization\")\n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>clouds</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>wind_gust</th>\n",
       "      <th>visibility</th>\n",
       "      <th>IsPublicHoliday</th>\n",
       "      <th>IsSchoolHoliday</th>\n",
       "      <th>IsHolidayPeriod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-20 00:00:00</td>\n",
       "      <td>9850.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1005</td>\n",
       "      <td>81</td>\n",
       "      <td>8.23</td>\n",
       "      <td>210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-20 01:00:00</td>\n",
       "      <td>9446.0</td>\n",
       "      <td>6.71</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>1005</td>\n",
       "      <td>76</td>\n",
       "      <td>8.23</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-20 02:00:00</td>\n",
       "      <td>9176.0</td>\n",
       "      <td>6.74</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>1004</td>\n",
       "      <td>81</td>\n",
       "      <td>9.26</td>\n",
       "      <td>210</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-20 03:00:00</td>\n",
       "      <td>9179.0</td>\n",
       "      <td>6.88</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>1003</td>\n",
       "      <td>81</td>\n",
       "      <td>9.26</td>\n",
       "      <td>210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-20 04:00:00</td>\n",
       "      <td>9346.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1002</td>\n",
       "      <td>76</td>\n",
       "      <td>7.20</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>2022-01-18 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1035</td>\n",
       "      <td>91</td>\n",
       "      <td>1.94</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.20</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>2022-01-18 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.49</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1035</td>\n",
       "      <td>91</td>\n",
       "      <td>1.28</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.31</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8733</th>\n",
       "      <td>2022-01-18 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1034</td>\n",
       "      <td>91</td>\n",
       "      <td>1.48</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.48</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8734</th>\n",
       "      <td>2022-01-18 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1034</td>\n",
       "      <td>92</td>\n",
       "      <td>1.39</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.37</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8735</th>\n",
       "      <td>2022-01-18 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1033</td>\n",
       "      <td>91</td>\n",
       "      <td>1.55</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.53</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8736 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Quantity  temp  feels_like  pressure  humidity  \\\n",
       "0     2021-01-20 00:00:00    9850.0  6.37       -0.83      1005        81   \n",
       "1     2021-01-20 01:00:00    9446.0  6.71       -0.59      1005        76   \n",
       "2     2021-01-20 02:00:00    9176.0  6.74       -1.11      1004        81   \n",
       "3     2021-01-20 03:00:00    9179.0  6.88       -0.95      1003        81   \n",
       "4     2021-01-20 04:00:00    9346.0  7.38        0.92      1002        76   \n",
       "...                   ...       ...   ...         ...       ...       ...   \n",
       "8731  2022-01-18 19:00:00       NaN  3.83        2.07      1035        91   \n",
       "8732  2022-01-18 20:00:00       NaN  3.49        3.49      1035        91   \n",
       "8733  2022-01-18 21:00:00       NaN  3.26        1.99      1034        91   \n",
       "8734  2022-01-18 22:00:00       NaN  3.00        1.83      1034        92   \n",
       "8735  2022-01-18 23:00:00       NaN  2.80        1.37      1033        91   \n",
       "\n",
       "      wind_speed  wind_deg  rain  snow  clouds  dew_point  wind_gust  \\\n",
       "0           8.23       210   0.0   0.0      75       3.35       0.00   \n",
       "1           8.23       200   0.0   0.0      75       2.78       0.00   \n",
       "2           9.26       210   0.5   0.0     100       3.71       0.00   \n",
       "3           9.26       210   0.0   0.0       0       3.85       0.00   \n",
       "4           7.20       200   0.0   0.0      75       3.43       0.00   \n",
       "...          ...       ...   ...   ...     ...        ...        ...   \n",
       "8731        1.94       101   0.0   0.0       5       2.35       2.20   \n",
       "8732        1.28        90   0.0   0.0       4       2.03       1.31   \n",
       "8733        1.48        89   0.0   0.0       3       1.85       1.48   \n",
       "8734        1.39        93   0.0   0.0       4       1.62       1.37   \n",
       "8735        1.55       111   0.0   0.0       3       1.41       1.53   \n",
       "\n",
       "      visibility  IsPublicHoliday  IsSchoolHoliday  IsHolidayPeriod  \n",
       "0        10000.0                0                0                0  \n",
       "1        10000.0                0                0                0  \n",
       "2        10000.0                0                0                0  \n",
       "3        10000.0                0                0                0  \n",
       "4        10000.0                0                0                0  \n",
       "...          ...              ...              ...              ...  \n",
       "8731     10000.0                0                0                0  \n",
       "8732     10000.0                0                0                0  \n",
       "8733     10000.0                0                0                0  \n",
       "8734     10000.0                0                0                0  \n",
       "8735     10000.0                0                0                0  \n",
       "\n",
       "[8736 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tim_input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TIM Setup\n",
    "The configuration below shows you all the options you have for setting up a forecast job with TIM. As you can see there are many possibilities however, TIM will by default already apply quite a lot of settings for you automatically. In this example we only set the \"predictionTo\" to \"24\" to generate a 24 sample ahead forecast and we'll set the \"outOfSampleRows\" to 24*100 = 2400 samples to apply backtesting on the last 100 days of the dataset. All other parameters are commented (#). If not set, TIM will assume default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_configuration = {\n",
    "#             \"name\": \"My first forecast job\",\n",
    "#             \"useCase\": {\"id\":\"useCaseId\"},\n",
    "#             \"experiment\": {\"id\":\"experimentId\"},\n",
    "            \"configuration\": {\n",
    "                \"predictionTo\": {\"baseUnit\": \"Sample\",\"value\": 24},\n",
    "#                 \"predictionFrom\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                 \"modelQuality\": \"Combined\",\n",
    "#                 \"normalization\": True,\n",
    "#                 \"maxModelComplexity\": 50,\n",
    "#                 \"features\": [\n",
    "#                    \"ExponentialMovingAverage\",\n",
    "#                     \"RestOfWeek\",\n",
    "#                     \"Periodic\",\n",
    "#                     \"Intercept\",\n",
    "#                     \"PiecewiseLinear\",\n",
    "#                     \"TimeOffsets\",\n",
    "#                     \"Polynomial\",\n",
    "#                     \"Identity\",\n",
    "#                     \"PublicHolidays\",      \n",
    "# #                     \"SimpleMovingAverage\",\n",
    "# #                     \"Month\",\n",
    "# #                     \"Trend\",\n",
    "# #                     \"DayOfWeek\",\n",
    "# #                     \"Fourier\",\n",
    "#                     ],\n",
    "#                 \"dailyCycle\": False,\n",
    "#                 \"allowOffsets\": True,\n",
    "#                 \"offsetLimit\": {\"type\": \"Explicit\",\"value\": 0},\n",
    "#                 \"memoryLimitCheck\": True,\n",
    "#                  \"predictionIntervals\": 90,\n",
    "#                  \"predictionBoundaries\": {\"type\": \"Explicit\",\n",
    "#                      \"maxValue\": 750,\n",
    "#                     \"minValue\": 100\n",
    "#                      },\n",
    "#                 \"rollingWindow\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "#                 \"backtest\": \"All\"\n",
    "                },\n",
    "            \"data\": {\n",
    "#                 \"version\": {\"id\":\"versionId\"},\n",
    "#                 \"inSampleRows\": {\"baseUnit\": \"Sample\",\"value\": 1},\n",
    "                \"outOfSampleRows\": {\"baseUnit\": \"Sample\",\"value\": 24*100},\n",
    "#                 \"imputation\": {\"type\": \"Linear\",\"maxGapLength\": 6},\n",
    "#                 \"columns\": [\n",
    "#                     1,\n",
    "#                     3,\n",
    "#                     \"wind\"\n",
    "#                     ],\n",
    "#                 \"targetColumn\": \"y\",\n",
    "#                 \"holidayColumn\": holidayColumn,\n",
    "#                 \"timeScale\": {\"baseUnit\": \"Hour\",\"value\": 1},\n",
    "#                 \"aggregation\": \"Mean\"\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configuration': {'predictionTo': {'baseUnit': 'Sample', 'value': 24}},\n",
       " 'data': {'outOfSampleRows': {'baseUnit': 'Sample', 'value': 2400}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_job_results_accuracy(response):   \n",
    "    bin_json = response['bin']\n",
    "    bin_accuracy_df = pd.DataFrame()\n",
    "    for n in bin_json:\n",
    "        bin_accuracy_df = bin_accuracy_df.append(pd.DataFrame(n).reset_index().rename(columns={'index':'KPI'}))\n",
    "    bin_accuracy_df['accuracy_type'] = 'bin'\n",
    "\n",
    "    samplesAhead_json = response['samplesAhead']\n",
    "    samplesAhead_accuracy_df = pd.DataFrame()\n",
    "    for n in samplesAhead_json:\n",
    "        samplesAhead_accuracy_df = samplesAhead_accuracy_df.append(pd.DataFrame(n).reset_index().rename(columns={'index':'KPI'}))\n",
    "    samplesAhead_accuracy_df['accuracy_type'] = 'samplesAhead'\n",
    "\n",
    "    all_accuracy_df = pd.DataFrame(response['all']).reset_index().rename(columns={'index':'KPI'})\n",
    "    all_accuracy_df['accuracy_type'] = 'all'\n",
    "    id_columns = ['KPI','name','accuracy_type']\n",
    "    acc_df = all_accuracy_df.append(samplesAhead_accuracy_df).append(bin_accuracy_df)\n",
    "    df = pd.melt(acc_df, id_vars=id_columns, value_vars=list(set(acc_df.columns)-set(id_columns)))\n",
    "    return df\n",
    "\n",
    "def get_forecast_job_results_model(response):\n",
    "    properties = response['model']['modelZoo']['variableProperties']\n",
    "    models = response['model']['modelZoo']['models']\n",
    "    \n",
    "    pi_df = pd.DataFrame(properties).sort_values(by='importance',ascending=False)\n",
    "    pi_df['rel_importance'] = pi_df['importance']/pi_df.sum()['importance']\n",
    "    \n",
    "    features = []\n",
    "    for m in models:\n",
    "        terms = m['terms']\n",
    "        for count,t in enumerate(terms):\n",
    "            f,b = find_feature(t['parts'])\n",
    "            features.append([m['index'],count,f,t['importance'],b])\n",
    "    fi_df = pd.DataFrame(features,columns=['Model','Term','Feature','importance','beta'])\n",
    "    return pi_df,fi_df,models\n",
    "\n",
    "def find_feature(sub_parts):\n",
    "    dow_list = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "    month_list = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "    features_list = []\n",
    "    for c,s in enumerate(sub_parts):\n",
    "        if   s['type']=='β':\n",
    "            sub_feature = ''\n",
    "        elif s['type']=='TimeOffsets':\n",
    "            sub_feature = s['predictor']+'(t'+str(s['offset'])+')'\n",
    "        elif s['type']=='RestOfWeek':\n",
    "            sub_feature ='DoW(t'+str(s['offset'])+') <= '+dow_list[s['day']-1]\n",
    "        elif s['type']=='Intercept':\n",
    "            sub_feature = 'Intercept('+str(int(s['value']))+')'\n",
    "        elif s['type']=='Cos':\n",
    "            sub_feature = 'Cos('+str(int(s['period']))+';'+s['unit']+')'\n",
    "        elif s['type']=='Sin':\n",
    "            sub_feature = 'Sin('+str(int(s['period']))+';'+s['unit']+')'\n",
    "        elif s['type']=='ExponentialMovingAverage':\n",
    "            sub_feature = 'EMA_'+s['predictor']+'(t'+str(int(s['offset']))+'; w='+str(int(s['window']))+')'\n",
    "        elif s['type']=='Identity':\n",
    "            sub_feature = s['predictor']\n",
    "        elif s['type']=='PiecewiseLinear':\n",
    "            sub_feature = 'max(0;'+str(s['subtype'])+'*('+str(round(s['knot'],6))+'-'+s['predictor']+'(t'+str(s['offset'])+')))'\n",
    "        elif s['type']=='SimpleMovingAverage':\n",
    "            sub_feature = 'SMA_'+s['predictor']+'(t'+str(int(s['offset']))+'; w='+str(int(s['window']))+')'\n",
    "        elif s['type']=='Fourier':\n",
    "            sub_feature = 'Fourier('+str(s['period'])+')'\n",
    "        elif s['type']=='Weekday':\n",
    "            sub_feature = 'DoW(t'+str(s['offset'])+') = '+dow_list[s['day']-1]\n",
    "        elif s['type']=='Month':\n",
    "            sub_feature = 'Month<='+month_list[s['month']]\n",
    "        elif s['type']=='PublicHoliday':\n",
    "            sub_feature = s['predictor']\n",
    "        elif s['type']=='Trend':\n",
    "            sub_feature = 'Trend'\n",
    "        else:\n",
    "            sub_feature = '_test_'\n",
    "        if s['type']=='β':\n",
    "            features_list.append(sub_feature)\n",
    "            beta = s['value']\n",
    "        else:\n",
    "            features_list.append(' & '+sub_feature) if c>0 else features_list.append(sub_feature)\n",
    "    feature_output = ''.join(str(e) for e in features_list)\n",
    "    return feature_output,beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. API Call\n",
    "In this section we communicate with TIM and first upload the dataset, for which you can provide a configuration if you want. Then, the configuration is sent to TIM to create and execute a forecasting job together with the uploaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_configuration = {\n",
    "#     \"timestampFormat\": \"yyyy-mm-dd HH:MM:SS.sss\",\n",
    "#     \"timestampColumn\": 1,\n",
    "#     \"decimalSeparator\": \".\",\n",
    "#     \"csvSeparator\": \",\",\n",
    "#     \"timeZone\": \"Z\",\n",
    "#     \"name\": \"Vienna\",\n",
    "#     \"description\": \"Electricity consumption\",\n",
    "#     \"samplingPeriod\": {\n",
    "#         \"baseUnit\": \"Hour\",\n",
    "#         \"value\": 1\n",
    "#     },\n",
    "#     \"workspace\": {\n",
    "#         \"id\": \"ef47117c-5408-4603-9d6f-735f45a74ff3\"\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_response = client.upload_dataset(dataset=tim_input_df,configuration=dataset_configuration,handle_status_poll=print)\n",
    "dataset_id = dataset_response[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_response = client.build_forecasting_model_and_execute(dataset_id=dataset_id,job_configuration=job_configuration,wait_to_finish=True,handle_status_poll=print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collect Results\n",
    "After the job is finished you can collect your results and insights from TIM using the functions below.\n",
    "You can use these tables with TIM outputs and adapt them to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_meta_data = forecast_response[0]\n",
    "properties_df,features_df,model = get_forecast_job_results_model(forecast_response[1])\n",
    "forecast_job_results_table_df = forecast_response[2]\n",
    "for i in forecast_job_results_table_df['forecast_type'].unique():\n",
    "    forecast_job_results_table_df.loc[forecast_job_results_table_df['forecast_type']==i, i] = forecast_job_results_table_df['forecast']\n",
    "accuracy_df = get_forecast_job_results_accuracy(forecast_response[3])\n",
    "job_logs_df = pd.DataFrame(forecast_response[4]).sort_values(by='createdAt').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_job_results_table_df['MAE'] = abs(forecast_job_results_table_df['forecast']-forecast_job_results_table_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualize Results\n",
    "Images below show how TIM results can be easily visualized in Python with Plotly. You can visualize the predictions, the accuracy values calculated by TIM, the predictor and feature importances and other insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = forecast_job_results_table_df\n",
    "fig = plt.subplots.make_subplots(rows=2, cols=1, vertical_spacing=0.04,shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['target'], name='Actuals', line=dict(color='black')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['Production'], name='Prediction', line=dict(color='goldenrod')), row=1, col=1)\n",
    "# fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['lower_bound'], name='Lower bound', line=dict(color='lightgrey')), row=1, col=1)\n",
    "# fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['upper_bound'], name='Upper bound', line=dict(color='lightgrey')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['InSample'], name='InSample', line=dict(color='green')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['OutOfSample'], name='OutOfSample', line=dict(color='red')), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['MAE'], name='MAE', line=dict(color='blue')), row=2, col=1)\n",
    "fig.update_layout(height=800, width=1200, title_text=\"Results\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = forecast_job_results_table_df[['target','OutOfSample']].dropna()\n",
    "x_axis = 'target'\n",
    "y_axis = 'OutOfSample'\n",
    "max_x = max(v_data[x_axis].max(),v_data[y_axis].max())\n",
    "min_x = min(v_data[x_axis].min(),v_data[y_axis].min())\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=v_data[x_axis], y=v_data[y_axis],mode='markers',name='results'))\n",
    "fig.add_trace(go.Scatter(x=[min_x,max_x], y=[min_x,max_x],mode='lines',name='y=x'))\n",
    "fig.update_layout(height=500, width=1200, title_text=\"Parity Plot\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = accuracy_df.dropna()['accuracy_type'].unique()\n",
    "columns = accuracy_df.dropna()['KPI'].unique()\n",
    "subplot_titles = []\n",
    "for i in rows:\n",
    "    for j in columns: subplot_titles.append(str(i)+\" \"+str(j))\n",
    "fig = plt.subplots.make_subplots(rows=len(rows), cols=len(columns), vertical_spacing=0.04,subplot_titles=subplot_titles)\n",
    "\n",
    "for r,i in enumerate(rows):\n",
    "    for c,j in enumerate(columns):\n",
    "        v_data = accuracy_df[(accuracy_df['KPI']==j)&(accuracy_df['accuracy_type']==i)].pivot(index=['KPI','name','accuracy_type'], columns='variable', values='value').reset_index()\n",
    "        fig.add_trace(go.Bar(x=v_data['name'], y=v_data['inSample'], name=str(i)+\" \"+str(j),text=round(v_data['inSample'],2),textposition='auto'), row=r+1, col=c+1)\n",
    "        fig.add_trace(go.Bar(x=v_data['name'], y=v_data['outOfSample'], name=str(i)+\" \"+str(j),text=round(v_data['outOfSample'],2),textposition='auto'), row=r+1, col=c+1)\n",
    "fig.update_layout(height=1200, width=1400, title_text=\"Data visualization\",)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_v_df = properties_df[properties_df['importance']>0]\n",
    "x_axis = 'name'\n",
    "y_axis = 'rel_importance'\n",
    "\n",
    "fig1 = go.Figure(go.Bar(x=b_v_df[x_axis], y=b_v_df[y_axis],text=round(b_v_df[y_axis],2),textposition='auto'))\n",
    "fig1.update_layout(height=500,width=1200,title_text='Predictor Importances',xaxis_title=x_axis,yaxis_title=y_axis)\n",
    "print('Predictors not used:'+str(list(properties_df[~(properties_df['importance']>0)]['name'])))\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(features_df, path=['Model','Feature'], values='importance',color='Feature')\n",
    "fig.update_layout(height=700,width=700,title_text='Feature Importances')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings = list(job_logs_df[job_logs_df['messageType'] == \"Warning\"]['message'])\n",
    "warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Results\n",
    "To save the outputs from TIM use the cells below. You can also find a summary of all the other functions in the Python Client for TIM below. \n",
    "For more information visit https://pypi.org/project/tim-client/ or our documentation https://docs.tangent.works/TIM-on-Platforms/Python-Client/Overview/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_job_results_table_df.to_csv('forecast_job_results_table_df.csv',index=False, float_format='%g')\n",
    "# accuracy_df.to_csv('accuracy_df.csv',index=False, float_format='%g')\n",
    "# properties_df.to_csv('properties_df.csv',index=False, float_format='%g')\n",
    "# features_df.to_csv('features_df.csv',index=False, float_format='%g')\n",
    "# job_logs_df.to_csv('job_logs_df.csv',index=False, float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.upload_dataset\n",
    "# client.delete_dataset\n",
    "# client.get_datasets\n",
    "# client.get_dataset_versions\n",
    "# client.build_forecasting_model\n",
    "# client.execute_forecast\n",
    "# client.build_forecasting_model_and_execute\n",
    "# client.clean_forecast\n",
    "# client.get_forecast_results\n",
    "# client.get_forecasting_jobs\n",
    "# client.delete_forecast\n",
    "# client.build_anomaly_detection_model\n",
    "# client.execute_anomaly_detection\n",
    "# client.build_anomaly_detection_model_and_execute\n",
    "# client.create_anomaly_detection\n",
    "# client.create_anomaly_detection_and_execute\n",
    "# client.get_anomaly_detection_results\n",
    "# client.get_anomaly_detection_jobs\n",
    "# client.delete_anomaly_detection\n",
    "# client.get_workspaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
